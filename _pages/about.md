---
permalink: /
layout: archive
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<!--![visualization of residual of iterative projection method for linear inequalities](../images/residual.png)-->
<figure style="float: left; margin-right:50px; width:100%"><img src="../images/residual.png" alt="visualization of residual of iterative projection method for linear inequalities"></figure>

I am an Assistant Professor in the [Mathematics Department](https://www.hmc.edu/mathematics/) at [Harvey Mudd College](https://www.hmc.edu/). My research focuses are in mathematical data science, optimization, and applied convex geometry.  I leverage mathematical tools, such as those from probability, combinatorics, and convex geometry, on problems in data science and optimization. Areas in which I have been active recently include randomized numerical linear algebra, combinatorial methods for convex optimization, tensor decomposition for topic modeling, network consensus and ranking problems, and community detection on graphs and hypergraphs.  My research is supported by NSF DMS \#2211318 "Tensor Models, Methods, and Medicine".

Before starting at HMC, I received my PhD in the [Graduate Group in Applied Mathematics](http://appliedmath.ucdavis.edu/) at the University of California, Davis where I was fortunate to be advised by [Professor Jesús A. De Loera](https://www.math.ucdavis.edu/~deloera), and then was a CAM Assistant Professor (post-doc) in the University of California, Los Angeles (UCLA) [Mathematics Department](https://ww3.math.ucla.edu/) where my exceptional postdoctoral mentor was [Professor Deanna Needell](https://www.math.ucla.edu/~deanna/).




<!--<br>Contact
===========
Email: <a href="mailto:jhaddock@g.hmc.edu">jhaddock@g.hmc.edu</a>
<br>Office: Shanahan 2408
<link href="https://assets.calendly.com/assets/external/widget.css" rel="stylesheet">
<script src="https://assets.calendly.com/assets/external/widget.js" type="text/javascript" async></script>
<a href="" onclick="Calendly.initPopupWidget({url: 'https://calendly.com/jamie-haddock'});return false;">Schedule time with me</a>-->



<br>Recent News
===========
<b>December '23: </b> I was recently elected secretary of the SIAM Activity Group on Data Science (SIAG-DATA).  The aim of SIAG-DATA is to advance the mathematics of data science, to highlight the importance and benefits of data science, to bring data science innovations to other areas of applied mathematics, and to identify and explore the connections between data science and other applied sciences.  One of the main activities of this group is the biennial conference on the Mathematics of Data Science (MDS).  I am also currently sitting on the organizing committee of this conference!  I am excited to help lead SIAG-DATA and continue to advance the many application of mathematics in data science.

<b>December '23: </b> My group's (with Paulina Hoyos Restrepo (UTA), Alona Kryshchenko (CSUCI), Deanna Needell (UCLA), Shambhavi Suryanarayanan (Princeton), and Karamatou Yacoubou-Djima (Wellesley)) proposal was accepted to Collaborate@ICERM!  We will be visiting for a week-long research visit in Summer 2024, where we will be studying randomized algorithms for tensor problems with factorized operators or data.  We are very excited for this opportunity!

<b>December '23: </b> My group's (with Paulina Hoyos Restrepo (UTA), Alona Kryshchenko (CSUCI), Shambhavi Suryanarayanan (Princeton), and Karamatou Yacoubou-Djima (Wellesley)) proposal was accepted to SLMath Summer Research in Mathematics (SRiM)!  We will be visiting for a two week-long research visit in Summer 2024, where we will be studying column-slice-action methods for tensor regression.  We are very excited for this opportunity!

<b>November '23: </b> I am co-editing a topical collection on tensor methods in La Matematica (the flagship journal of the Association for Women in Mathematics) with Anna Konstorum (IDA/CCS) and Anna Ma (UCI)!  Research in tensor (multidimensional array) analysis is accelerating, driven by the increasing complexity of data sets, arising from fields such as biomedical engineering, networks, and the physical and social sciences, which naturally lend themselves to a tensor structure. We invite research, survey, and review articles on novel theoretical, computational, and real-world application progress in tensor analysis. Our goal is to bring together new developments in tensor analysis into a Topical Collection at La Matemetica in order to give interested readers a broad and up-to-date opportunity to learn about new work in tensor analysis thereby lowering the barrier for entry into the field, and to feature wide array of research and researchers in this field.

<b>November '23: </b> I am coorganizing a workshop titled "Women in Randomized Numerical Linear Algebra" at the Institute for Pure and Applied Mathematics (IPAM) in summer 2025 with Malena Espanol (ASU), Anna Ma (UCI), and Deanna Needell (UCLA).  We are excited to bring together an amazing group of researchers focused on this exciting topic!

<b>October '23: </b> Our paper (with students Tyler Will, Joshua Vendrow, Runyu Zhang, Mengdi Gao, and Eli Sadovnik, and colleagues Denali Molitor and Deanna Needell)  <a href="https://arxiv.org/abs/2303.00058">Neural Nonnegative Matrix Factorization for Hierarchical Multilayer Topic Modeling</a> was accepted to the "Sampling Theory, Signal Processing, and Data Analysis" journal!  In this paper, we introduce a new model based on nonnegative matrix factorization (NMF) for detecting latent hierarchical structure in data, which we call Neural NMF.  This model frames hierarchical NMF as a neural network, and we provide theoretical results which allow us to train Neural NMF via a natural backpropagation method. We illustrate the promise of this model with several numerical experiments on benchmark datasets and real world data.

<b>August '23: </b> I have a few talks and trips this Fall!  I will be speaking in the <a href="https://sites.google.com/view/minds-seminar/home">One World Mathematics of INformation, Data, and Signals (1W-MINDS) Seminar</a> on September 7th at 11:30 am PT on Zoom.  My talk is titled "Randomized Kaczmarz Methods: Corruption, Consensus, and Concentration."  Later in the month, I will speak at the <a href="https://allerton.csl.illinois.edu/">Fifty-Ninth Annual Allerton Conference on Communication, Control, and Computing</a> in Monticello, IL on our (with collaborators Anna Ma and Liza Rebrova) paper <a href="http://arxiv.org/abs/2308.07987">“On Subsampled Quantile Randomized Kaczmarz”</a>.  After that, I go to Atlanta, GA for the <a href="https://awm-math.org/meetings/awm-research-symposium/">AWM Research Symposium</a> where I will be speaking in the session "Tensor Methods for data modeling" on Saturday, September 30.  My talk is titled "Hierarchical nonnegative tensor factorizations and applications."  The last leg of the trip is to Boston, MA where I will visit Wellesley College to give a talk on Monday, October 2.

<b>August '23: </b> Our (with collaborators Anna Ma and Liza Rebrova) paper <a href="http://arxiv.org/abs/2308.07987">“On Subsampled Quantile Randomized Kaczmarz”</a> was accepted to the the <a href="https://allerton.csl.illinois.edu/">Fifty-Ninth Annual Allerton Conference on Communication, Control, and Computing</a> to be held in Monticello, Illinois during September 26-29, 2023.  In this paper, we provide theoretical guarantees for the Quantile Randomized Kaczmarz method using subsamples of the linear system residual in each iteration.  Previous guarantees required computing the entire residual which is often (or nearly always) infeasible.  We're excited to participate in this wonderful conference!

<!--

<b>June '23: </b> I've published all course materials for my course <a href="https://github.com/jamiehadd/Math189AD-MathematicalDataScienceAndTopicModeling">"Mathematical Data Science & Topic Modeling"</a>!  All slides, code, and assignments are available and free to be used, edited, and shared.  If you find use of these materials, please cite this repository and consider letting me know your impressions and any typos/errors you catch!

<b>May '23: </b> I'm serving on the organizing committee for the third SIAM Conference on the Mathematics of Data Science (SIAM MDS) in 2024!  SIAM MDS is a biennial conference of the SIAM Activity Group on Data Science and “aims to bring together those who are building foundations for data science and its applications across science, engineering, technology, and society.” The organizing committee shapes and defines the scientific program of the conference, e.g., identify invited speakers, choose mini-tutorials, etc.  I'm very excited to help plan this amazing conference!



<b>April '23: </b> I was featured in the April 2023 Academic Data Science Alliance (<a href="https://academicdatascience.org/">ADSA</a>) Career Development Network Round-up (newsletter) and <a href="https://academicdatascience.org/resources/meet-a-data-scientist-jamie-haddock/">blog</a>!

<b>March '23: </b> We (with students Tyler Will, Joshua Vendrow, Runyu Zhang, Mengdi Gao, and Eli Sadovnik, and colleagues Denali Molitor and Deanna Needell) submitted our paper <a href="https://arxiv.org/abs/2303.00058">Neural Nonnegative Matrix Factorization for Hierarchical Multilayer Topic Modeling</a>!  In this paper, we introduce a new model based on nonnegative matrix factorization (NMF) for detecting latent hierarchical structure in data, which we call Neural NMF.  This model frames hierarchical NMF as a neural network, and we provide theoretical results which allow us to train Neural NMF via a natural backpropagation method. We illustrate the promise of this model with several numerical experiments on benchmark datasets and real world data.



<b>February '23: </b> I will give the plenary talk for the residential component of the <a href="https://www.hmc.edu/admission/wistem/">Harvey Mudd College  "Women’s Inclusion in Science, Technology, Engineering, and Mathematics (WISTEM)" program</a>.  WISTEM is a 6-month program that requires participants to engage with an on-campus residential component and interactive online sessions. Through the virtual program and visit to campus, WISTEM will connect participating students with a cohort of like-minded peers, help participants learn more about admission, and strengthen their understanding of the experiences of women in STEM, with a particular focus on the experiences of women of color.  I'm very excited to be involved with this great program and to meet some fabulous high school students!

<b>January '23: </b> Our paper (with students Hannah Friedman, Amani R. Maina-Kilaas, Julianna Schalkwyk, and Hina Ahmed) <a href="https://arxiv.org/abs/2207.05112">An Interpretable Joint Nonnegative Matrix Factorization-Based Point Cloud Distance Measure</a> was accepted for presentation at and publication in the proceedings of the 57th Annual Conference on Information Sciences and Systems (CISS) at Johns Hopkins University!  We will present this paper at the conference March 22-24, 2023.



<b>December '22: </b> I have some upcoming visits and talks in early Spring!  I will be visiting Caltech on January 25th to speak in the <a href="http://cmx.caltech.edu/">Computational Mathematics + X (CMX) Lunch Seminar</a>.  I will be spending a half-day for lunch and meetings in the afternoon after my talk!  Additionally, I will be visiting UCI on February 22nd to speak in the <a href="https://www.math.uci.edu/seminar_list/Combinatorics%20and%20Probability">Probability and Combinatorics Seminar</a>!  I will be spending the afternoon on campus for lunch and meetings also.

<b>December '22: </b> I had the opportunity to speak in the "Multi-Modal Imaging with Deep Learning and Modeling" workshop at IPAM!  This was a great week-long workshop in the long program "Computational Microscopy".  My <a href="https://youtu.be/0-kwIBAQ1hg">talk</a> was titled "Hierarchical and Neural Nonnegative Tensor Decompositions" and presented several works developing hierarchical topic models for tensor data.  Thanks to the organizers for a great program!

<b>November '22: </b> Our paper (with collaborators Phil Chodrow and Nicole Eikmeier) <a href="https://arxiv.org/abs/2204.13586">Nonbacktracking spectral clustering of nonuniform hypergraphs</a> was accepted to SIAM Journal on Mathematics of Data Science (SIMODS)!  In this paper, we propose methods for community detection on nonuniform (containing edges of different sizes) hypergraphs -- one is a simple spectral approach using the nonbacktracking operator and the other is an alternating approach based upon linearized belief-propagation (the nonbacktracking operator appears here too!).  We additionally provide some theorems that improve computational complexity of working with the nonbacktracking operator and other large matrices appearing in our methods.

<b>November '22: </b> Our paper <a href="https://arxiv.org/pdf/2209.02415v1.pdf">Interpretability of Automatic Infectious Disease Classification Analysis with Concept Discovery</a> was accepted to the <a href="https://ml4health.github.io/2022/">Machine Learning 4 Health (ML4H)</a> conference!  This paper will be presented as a poster in New Orleans at the end of November 2022.



<b>October '22: </b> The international seminar <a href="https://sites.google.com/view/minds-seminar/home">One World Mathematics of Information, Data, and Signals (MINDS)</a> has created a Slack workspace for sharing announcements of interest to our community and connecting with other members!  If you are interested in joining this Slack workspace, please follow the link provided at the top of our <a href="https://sites.google.com/view/minds-seminar/home">1W-MINDS website</a>.


<b>August '22: </b> Our paper (with student Chen Yap and collaborator Ben Jarman) <a href="https://arxiv.org/abs/2110.14609">Paving the Way for Consensus: Convergence of Block Gossip Algorithms</a> was accepted to the IEEE Transactions on Information Theory journal!  In this paper, we prove a new convergence bound for a broader class of randomized block Kaczmarz methods on a broader class of inconsistent linear systems, then utilize this convergence bound to prove convergence of the block gossip methods for average consensus.  We additionally specify the result to three popular types of block gossip protocols which utilize specific subgraph structures to iteratively update towards consensus.



<b>June '22: </b> In 2022-2023, I am co-organizing the <a href="https://sites.google.com/view/minds-seminar/home">One World Mathematics of Information, Data, and Signals (MINDS) Seminar</a>!  Given the impossibility of travel during the COVID-19 crisis the One World MINDS seminar was founded as an inter-institutional global online seminar aimed at giving researchers interested in mathematical data science, computational harmonic analysis, and related applications access to high quality talks. Talks are held on Thursdays either at 2:30 pm New York time or at 4:30 pm Shanghai/ 9:30 am (summer 10:30 am) Paris time.

<b> June '22: </b> Our (with co-organizer Phil Chodrow) minisymposium on "Tensor Methods for Network Data Science" was accepted to the SIAM Conference on the Mathematics of Data Science (MDS22) which is to be held in San Diego, CA in September 2022!  We have four fabulous speakers, Izabel P. Aguiar (Stanford University), Tamara Kolda (MathSci.ai), “Bill” Feng Shi (TigerGraph), and Francesco Tudisco (GSSI), who will speak about the exciting new developments of tensor-based methods for data science problems related to networks.

<b> June '22: </b> This month I have the honor of speaking in the Harvey Mudd College <a href="https://www.hmc.edu/calendar/events/stauffer-lecture-tensor-models-methods-and-medicine-jamie-haddock/">Stauffer Lecture series</a> where I will describe my work in "Tensor Models, Methods, and Medicine."  Additionally, I will speak (virtually) to the Rice University <a href="https://datascience.ericchi.com/#:~:text=Data%20Scientists%20in%20Training%20Outreach,data%20science%20methods%20and%20careers.">"Data Scientists in Training" Outreach Program</a> where I will describe my path to research in mathematical data science!


<b>May '22: </b> Check out this *amazing* <a href="https://youtu.be/SclGSdwB7M4">video</a> my summer 2021 research student Hannah Kaufman made!  In it, she illustrates how the Kaczmarz method works for solving linear systems, and presents an application to the problem of rating items according to pairwise comparison information.  Way to go, Hannah!!



<b>April '22: </b> We (with collaborators Phil Chodrow and Nicole Eikmeier) submitted our paper <a href="https://arxiv.org/abs/2204.13586">Nonbacktracking spectral clustering of nonuniform hypergraphs</a>!  In this paper, we propose methods for community detection on nonuniform (containing edges of different sizes) hypergraphs -- one is a simple spectral approach using the nonbacktracking operator and the other is an alternating approach based upon linearized belief-propagation (the nonbacktracking operator appears here too!).  We additionally provide some theorems that improve computational complexity of working with the nonbacktracking operator and other large matrices appearing in our methods.

<b>April '22: </b> Our (with student Edwin Chau) paper <a href="https://arxiv.org/abs/2010.10635">On Application of Block Kaczmarz Methods in Matrix Factorization</a> was accepted to SIAM Undergraduate Research Online (SIURO)!  In this work, we discuss and test a block Kaczmarz solver that replaces the least-squares subroutine in the common alternating scheme for matrix factorization. This variant trades a small increase in factorization error for significantly faster algorithmic performance. In doing so we find block sizes that produce a solution comparable to that of the least-squares solver for only a fraction of the runtime and working memory requirement!



<b>March '22: </b> I am participating in the <a href="https://www.ias.edu/math/wam/program-years/2022-program-women-and-mathematics">IAS Women and Mathematics “The Mathematics of Machine Learning"</a> at the Institute of Advanced Studies in Princeton, NJ!  This program will be held from May 21-27, 2022 and will feature lectures by Cynthia Rudin (Duke University) and Maria-Florina Balcan (Carnegie Mellon University).  Looking forward to meeting an exceptional group of faculty and students and learning about some great new topics!

<b>March '22: </b> I am participating in the <a href="https://www.ams.org/programs/research-communities/2022MRC-HyperNet">AMS MRC program "Models and Methods for Sparse (Hyper)Network Science "</a> as an assistant to the organizers!  This program will be held June 5-11, 2022 at Beaver Hollow Conference Center in Java Center, NY and will deal with graph and hypergraph models and their applications to real world study of critical systems.  Looking forward to the opportunity to learn and network with this exceptional community.

<b>March '22: </b> I am co-organizing the Southern California Applied Mathematics Symposium (SOCAMS) with Heather Zinn-Brooks (Harvey Mudd College), Christina Edholm (Scripps College), Manuchehr Aminian (Cal Poly Pomona), Phil Chodrow (UCLA), Anna Ma (UCI), Adam MacLean (USC), Chris Miles (UCI), and Alona Kryshchenko (CSU Channel Islands).  This one-day meeting will be held on the campus of Harvey Mudd College on May 21, 2022!  This conference aims to bring together researchers from universities throughout Southern California, working in all areas of Applied Mathematics, for a one-day exchange of ideas in an informal and collaborative atmosphere. More information and registration available at <a href="https://www.socams.org">https://www.socams.org"</a>!



<b>February '22: </b> Elizaveta Rebrova (Princeton Univ. ORFE) and I are organizing sessions titled "Randomized Iterative Methods beyond Least-squares" and "Tensor Modeling and Optimization" for the "Optimization for Data Science and Machine learning" cluster at the seventh <a href="https://iccopt2022.lehigh.edu/">International Conference on Continuous Optimization (ICCOPT)</a> which will take place at Lehigh University in Bethlehem, Pennsylvania during July 25-28, 2022.  We have two great slates of speakers organized to speak on these topics!

<b>February '22: </b>Applications are now open for my funded summer undergraduate research projects <a href="https://uro.hmc.edu/projects">Tensor Models and Methods for Medical Imaging</a>, <a href="https://uro.hmc.edu/projects">Numerical Linear Algebraic Analyses of Opinion Dynamics on Networks</a>, and <a href="https://uro.hmc.edu/projects">Iterative Methods for Large-scale Systems of Linear Equations</a>!  Applications may be submitted via the HMC URO portal until February 20.



<b>January '22: </b> Our (with student <a href="http://www.joshvendrow.com/">Josh Vendrow</a>) paper <a href="https://arxiv.org/abs/2109.14820">A Generalized Hierarchical Nonnegative Tensor Decomposition</a> was accepted to the 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)!  In this paper, we propose a hierarchical tensor decomposition model that generalizes a natural model for matrices, a property which many hierarchical tensor decomposition models lack.  This model naturally illuminates the hierarchy of latent topics in tensor-structured data.

<b>January '22: </b> I am coorganizing the MAA Session "Establishing Interdisciplinary Collaborations in Teaching and Research" at the Joint Mathematics Meeting (virtual) April 6-9, 2022 with Jessica Oehrlein (Fitchburg State University)!  Due to the transition to virtual format and the challenges of scheduling, this session will occur in March.  We have a great set of speakers who will lead an interactive session on how beginning and sustaining interdisciplinary collaboration with academics outside mathematics and industrial colleagues.


<b>December '21: </b> Our paper <a href="https://arxiv.org/abs/2009.08089">Quantile-based Iterative Methods for Corrupted Systems of Linear Equations</a> was accepted for publication in SIAM Journal on Matrix Analysis and Applications (SIMAX)!  In this paper, we propose iterative methods for solving large-scale and arbitrarily corrupted systems of equations.  We provide both theoretical and empirical evidence of the promise of these methods; our theoretical results build upon new and classical results in high-dimensional probability.



<b>November '21: </b> We (with student Chen Yap) submitted our paper <a href="https://arxiv.org/abs/2110.14609">Paving the Way for Consensus: Convergence of Block Gossip Algorithms</a>!  In this paper, we prove a new convergence bound for a broader class of randomized block Kaczmarz methods on a broader class of inconsistent linear systems, then utilize this convergence bound to prove convergence of the block gossip methods for average consensus.  We additionally specify the result to three popular types of block gossip protocols which utilize specific subgraph structures to iteratively update towards consensus.



<b>September '21: </b> Our papers "Neural Nonnegative CP Decomposition for Hierarchical Tensor Analysis" (with student <a href="http://www.joshvendrow.com/">Josh Vendrow</a>) and <a href="https://arxiv.org/abs/2010.07956">"Semi-supervised Nonnegative Matrix Factorization for Document Classification"</a> (with student Sixian Li) were accepted to the proceedings of the 55th Asilomar Conference on Signals, Systems, and Computers!  During that conference, I will additionally chair the session "Algorithms for Data Analytics".



<b>June '21: </b> I was selected for the MAA Project NExT Gold'21 cohort!  <a href="https://www.maa.org/programs-and-communities/professional-development/project-next">Project NExT</a> (New Experiences in Teaching) is a year-long professional development program for early career mathematicians that addresses all aspects of an academic career. Looking forward to participating in this program and to meeting the rest of the cohort!

<b>May '21: </b> Our grant <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2111440&HistoricalAwards=false">"Tensor Models, Methods, and Medicine"</a> was awarded by NSF DMS Computational Mathematics!  This award will support research developing supervised and hierarchical tensor models and efficient numerical and combinatorial methods for training these models, and an exciting collaboration with cardiologists at Harbor-UCLA Medical Center!  It will fund summer undergraduate research positions and summer workshops bringing experts on the mathematics of tensors together with application area experts.  If you are interested in either of these opportunities, please <a href="mailto:jhaddock@g.hmc.edu">reach out!</a>

<b>May '21: </b> We submitted our paper <a href="https://arxiv.org/abs/2105.09065">Statistical Learning for Best Practices in Tattoo Removal</a> (with student Richard Yim)!  This paper employs statistical and machine learning techniques to investigate best practices in laser-assisted tattoo removal.  This work is a collaboration with the largest gang rehabilitation and reentry organization in the world, <a href="https://homeboyindustries.org/">Homeboy Industries</a>!

<dt><h3>[Feb. '21]</h3></dt> <dd>Applications are now open for my funded summer undergraduate research project <a href="https://uro.hmc.edu/projects">Kaczmarz Methods for Large-scale Data Analysis</a>!  This project will be run in conjunction with the UCLA CAM REU and is partially funded by Harvey Mudd College.  Applications from undergraduates at any institution are welcome and can be submitted through <a href="https://www.mathprograms.org/db/programs/1067">MathPrograms</a>! If you are a Claremont colleges student, you can additionally apply at <a href="https://uro.hmc.edu/projects">HMC URO</a>.</dd>
<dt><h3>[Jan. '21]</h3></dt> <dd>Our paper <a href="https://arxiv.org/abs/2010.11365">On a Guided Nonnegative Matrix Factorization</a> (with student Josh Vendrow) was accepted to the 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)!  In it, we propose an approach based upon the nonnegative matrix factorization (NMF) model, deemed Guided NMF, that incorporates user-designed seed word supervision. Our experimental results demonstrate the promise of this model and illustrate that it is competitive with other methods of this ilk with only very little supervision information!</dd>
<dt><h3>[Dec. '20]</h3></dt> <dd>Our paper <a href="http://arxiv.org/abs/1912.03544">Greed Works: An Improved Analysis of Sampling Kaczmarz-Motzkin</a> (with Anna Ma) was accepted for publication to the SIAM Journal on Mathematical Data Science (SIMODS)!  In this work, we present an improved convergence analysis of the Sampling Kaczmarz-Motzkin (SKM) family of methods on consistent systems of linear equations.  Our analysis illustrates the advantage of using greedier members of this family and presents intuition for why Motzkin's (maximal residual) method often converges faster than the Randomized Kaczmarz method! We additionally specialize our analysis to two specific forms of linear systems, including average consensus systems.</dd>
<dt><h3>[Nov. '20]</h3></dt> <dd>Our paper <a href="https://arxiv.org/abs/1905.13404">Data-driven Algorithm Selection and Tuning in Optimization and Signal Processing</a> was accepted for publication to the Annals of Mathematics and Artificial Intelligence! In this paper, we train machine learning methods to automatically improve the performance of optimization and signal processing algorithms. As a proof of concept, we use our approach to improve two popular data processing subroutines in data science: stochastic gradient descent and greedy methods in compressed sensing!</dd>
<dt><h3>[Oct. '20]</h3></dt> <dd>We (with student Edwin Chau) submitted the paper <a href="https://arxiv.org/abs/2010.10635">On Application of Block Kaczmarz Methods in Matrix Factorization</a>!  In this work, we discuss and test a block Kaczmarz solver that replaces the least-squares subroutine in the common alternating scheme for matrix factorization. This variant trades a small increase in factorization error for significantly faster algorithmic performance. In doing so we find block sizes that produce a solution comparable to that of the least-squares solver for only a fraction of the runtime and working memory requirement!</dd>
<dt><h3>[Oct. '20]</h3></dt> <dd>We (with student Sixian Li) submitted the paper <a href="http://arxiv.org/abs/2010.07956">Semi-supervised NMF Models for Topic Modeling in Learning Tasks</a>!  In this work, we propose several new semi-supervised NMF (SSNMF) models and show that these are naturally formulated as the maximum likelihood estimators given a generative factorization model and assumed distributions of uncertainty in the observed data.  We develop training methods for the general forms of these models and illustrate how to apply them to the classification task; our experiments show that these methods are very promising and achieve high classification accuracy on the 20 Newsgroups data (while also developing a coherent topic model and classifying in a low-dimensional space)!</dd>
<dt><h3>[Sep. '20]</h3></dt> <dd>We (with student Josh Vendrow) submitted the paper "Neural Nonnegative CP Decomposition for Hierarchical Tensor Analysis"!  We propose a model for hierarchical tensor decomposition and a neural network-inspired technique for training the model.  This model allows a user to decompose a tensor at different granularities (ranks) and to visualize the relationship between the learned topics at different levels of hierarchy!</dd>
<dt><h3>[Sep. '20]</h3></dt> <dd>We submitted the paper <a href="https://arxiv.org/abs/2009.08089">Quantile-based Iterative Methods for Corrupted Systems of Linear Equations</a>!  In this paper, we propose iterative methods for solving large-scale and arbitrarily corrupted systems of equations.  We provide both theoretical and empirical evidence of the promise of these methods; our theoretical results build upon new and classical results in high-dimensional probability.</dd>
<dt><h3>[Sep. '20]</h3></dt> <dd>We submitted the paper "Weakly-Supervised Object Localization using Semi-supervised Nonnegative Matrix Factorization"!  We combine a new form of semi-supervised nonnegative matrix factorization with convolutional neural network filters to produce a successful model for object localization in multi-class image datasets.</dd>
<dt><h3>[Sep. '20]</h3></dt> <dd>Our paper <a href="https://arxiv.org/abs/2001.00631">On Large-Scale Dynamic Topic Modeling with Nonnegative CP Tensor Decomposition</a> was accepted for publication in the Proceedings of the Women in Data Science and Mathematics (WiSDM) Workshop!  This collaboration was begun at the Research Collaboration Workshop for <a href="https://icerm.brown.edu/topical_workshops/tw19-5-wisdm/">Women in Data Science and Mathematics</a>, July 2019 held at <a href="https://icerm.brown.edu/">ICERM</a> (funded by ICERM, <a href="https://awm-math.org/">AWM</a> and <a href="http://dimacs.rutgers.edu/">DIMACS</a> (NSF grant CCF1144502)).</dd>
<dt><h3>[Aug. '20]</h3></dt> <dd>We (with student Josh Vendrow) submitted the paper <a href="https://arxiv.org/abs/2009.09087">Feature Selection on Lyme Disease Patient Survey Data</a>!  In this work, we use basic machine learning techniques to perform feature selection on a large-scale survey dataset from a private Lyme disease patient database, <a href="https://www.lymedisease.org/mylymedata-lyme-disease-research/">MyLymeData</a>.</dd>
<p>I received the AMS-Simons Foundation Travel Grant for 2018-2020.</p> -->
